cat(paste0("Date:", Sys.Date(),'\n')) #Overwrite the file
diab.data <- select_outcome(data, "diabetes", cov.indiv)
plot_bin_cont_relationship(diab.data, "diabetes", "age")
test_age_disease_linearity("diabetes", diab.data)
print("Quadratic relationship between age and diabetes.")
diab.log.1 <- glm(diabetes ~ age + sex + difficulties + education + swiss, data = diab.data, family = "binomial")
print_model_summary(diab.log.1)
diab.log.2 <- update(diab.log.1,  '~ . + I(age^2)')
print_model_summary(diab.log.2)
compare_models(diab.log.1, diab.log.2)
diab.data <- diab.data %>% mutate(diabetes_adj = unname(resid(diab.log.2, type = "pearson")))
sink()
# DYSLIPIDEMIA ------------------------------------------------------------
sink("../results/regression_models/dyslipidemia/confounders_adjustment_dyslipidemia.txt")
cat(paste0("Date:", Sys.Date(),'\n')) #Overwrite the file
dys.data <- select_outcome(data, "dyslipidemia", cov.indiv)
plot_bin_cont_relationship(dys.data, "dyslipidemia", "age")
test_age_disease_linearity("dyslipidemia", dys.data)
print("Quadratic relationship between age and dyslipidemia.")
dys.log.1 <- glm(dyslipidemia ~ age + sex + difficulties + education + swiss, data = dys.data, family = "binomial")
print_model_summary(dys.log.1)
dys.log.2 <- update(dys.log.1,  '~ . + I(age^2)')
print_model_summary(dys.log.2)
compare_models(dys.log.1, dys.log.2)
dys.data <- dys.data %>% mutate(dyslipidemia_adj = unname(resid(dys.log.2, type = "pearson")))
sink()
# MERGE & SAVE ------------------------------------------------------------
# Left join with dataset
adjusted_outcomes <- data %>% dplyr::select(-all_of(cov.indiv)) %>%
left_join(hyp.data %>% dplyr::select(pt, hypertension_adj), by='pt') %>%
left_join(obes.data %>% dplyr::select(pt, obesity_adj), by='pt') %>%
left_join(diab.data %>% dplyr::select(pt, diabetes_adj), by='pt') %>%
left_join(dys.data %>% dplyr::select(pt, dyslipidemia_adj), by='pt')
# threshold <- 4/length(diab.model$residuals)
# diab.data %>% filter(diabetes_cooks_dist > threshold)
# # Save potential outliers (influential observations) to file
# diab.outliers <- diab.data %>% filter(diabetes_cooks_dist > threshold)
# # inner_join(diab.outliers, outcomes %>% dplyr::select(pt, geometry), by="pt") %>% st_write("outliers.geojson")
# Save to file
st_write(adjusted_outcomes, paste0("../processed_data/f2_adjusted_outcomes.gpkg"), driver='GPKG', delete_layer=TRUE)
DBI::dbDisconnect(con)
# # CARDIOVASCULAR DISEASES -------------------------------------------------
#
# sink("../results/regression_models/cvd/spatial_variation_risk_cvd.txt")
# cat(paste0("Date:", Sys.Date(),'\n')) #Overwrite the file
#
# cvd.data <- select_outcome(data_std, "cvd", cov.indiv, cov.env)
#
# # CVD adjustment
# plot_bin_cont_relationship(cvd.data, "cvd", "age")
# print("The graph age / CVD may indicate a non linear relationship between the two variables.")
#
# test_age_disease_linearity("cvd", cvd.data)
# print("Adding quadratic and cubic term do result in a substantial improvment of the model so we keep the linear term only.")
#
# cvd.log.1 <- glm(cvd ~ age + sex, data = cvd.data, family = "binomial")
# print_model_summary(cvd.log.1)
# vif(cvd.log.1)
#
# cvd.log.2 <- update(cvd.log.1,  '~ . + education + difficulties')
# print_model_summary(cvd.log.2)
# compare_models(cvd.log.1, cvd.log.2)
# vif(cvd.log.2)
#
# print("Remove financial difficulties who do not seem to contribute to CVD risk.")
#
# cvd.log.3 <- update(cvd.log.2,  '~ . + swiss + cohabiting')
# print_model_summary(cvd.log.3)
# compare_models(cvd.log.2, cvd.log.3)
# vif(cvd.log.3)
#
# cvd.log.4 <- update(cvd.log.1, '~ . + education')
# print_model_summary(cvd.log.4)
# compare_models(cvd.log.1, cvd.log.4)
#
#
# cvd.model.adj <- cvd.log.4
# cvd.data <- cvd.data %>% mutate(cvd_adj = unname(resid(cvd.model.adj, type = "pearson")))
#
# # OLS with characteristics of the living environment
#
# cvd.ols.1 <-lm(cvd_adj ~ PTOT + GREEN_SP + NOISE + PM25 + MEDREV + R_UNEMP + R_NN_POBL + R_FFB, data=cvd.data)
# print_model_summary(cvd.ols.1)
# vif(cvd.ols.1)
#
# cvd.ols.2 <- cvd.ols.1 %>% step( direction = "backward", trace = 1)
#
# cvd.ols.3 <- lm(cvd_adj ~ R_NN_POBL, data=cvd.data)
# print_model_summary(cvd.ols.3)
#
# compare_models(cvd.ols.1, cvd.ols.3)
#
# # cvd.test <- glm(cvd ~ age  + sex + PTOT + GREEN_SP + NOISE + PM25 + MEDREV + R_UNEMP + R_NN_POBL + R_FFB, data=cvd.data, family="binomial")
# # print_model_summary(cvd.test)
# # Add environmental characteristics
# ha = read_sf(con, query="SELECT reli, PTOT, GREEN_SP, NOISE, PM25, MEDREV, R_UNEMP, R_NN_POBL, R_FFB, geometry FROM geochronic.ha_characteristics WHERE st_intersects(geometry, (SELECT geometry FROM lausanne_sectors_extent))")
# names(ha)[names(ha) != c("reli", "geometry")] <- toupper(names(ha)[names(ha) != c("reli", "geometry")])
#
# # Merge
# data <- inner_join(ha %>% st_drop_geometry(), data, by="reli") %>% st_drop_geometry()
# assess_normality <- function(df, var){
#   distrib <- ggplot(df) +
#     geom_histogram(aes(x = !!sym(var)), fill = "steelblue", alpha = 0.5) +
#     theme_minimal()
#   print(distrib)
#   shapiro.test(df[[var]])
# }
#
# assess_normality(data, "GREEN_SP")
# assess_normality(data, "PTOT")
# assess_normality(data, "NOISE")
# assess_normality(data, "PM25")
# assess_normality(data, "NO2")
# assess_normality(data, "MEDREV")
# assess_normality(data, "R_UNEMP")
# assess_normality(data, "R_NN_POBL")
# assess_normality(data, "R_FFB")
# assess_normality(data, "R_NN_FRA")
#
# log_vars <- c("PM25", "NO2")
#
# # Standardize environmental variables
# data_std <- data %>%
#   mutate_at(log_vars, ~ log(.))
#
# data_std <- data %>%
#   mutate_at(cov.env, ~ scale(.)[,1])
gc()
# Compute the Ordinatry Least Squares Regression (OLS) to be compared with GWR/MGWR, and that will be used to assess VIF
require(RPostgreSQL)
require(car)
require(tidyverse)
require(sf)
require(DBI)
setwd("/mnt/data/GEOSAN/RESEARCH PROJECTS/GEOCHRONIC @ LASIG (EPFL)/GEOSAN-geochronic/src/")
source('/mnt/data/GEOSAN/FUNCTIONS/GIRAPH-functions/geosan_funcs/password_utils.R')
con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",rstudioapi::askForPassword(),dbname="geosan")
# LOAD DATASETS -----------------------------------------------------------
ha <- read_sf(con, query="SELECT * FROM geochronic.ha_characteristics") %>% st_drop_geometry()
indiv =  st_read("../processed_data/f2_adjusted_outcomes.gpkg") %>% st_drop_geometry()
cov <- c("INTDEN", "GREEN_SP", "NOISE", "PM25", "NO2", "MEDREV", "R_UNEMP", "R_NN_POBL", "R_NN_CH")
data.obesity <- indiv %>% inner_join(ha, by="reli")
data.obesity <- indiv %>%
inner_join(ha, by="reli") %>%
filter(!is.na(obesity_adj)) %>%
dplyr::select(obesity_adj, all_of(cov))
ha <- ha %>% rename_with(~ toupper(.), -c(reli,geometry))
ha <- ha %>% rename_with(~ toupper(.), -c(reli))
ha <- read_sf(con, query="SELECT * FROM geochronic.ha_characteristics") %>% st_drop_geometry()
ha <- ha %>% rename_with(~ toupper(.), -c(reli))
indiv =  st_read("../processed_data/f2_adjusted_outcomes.gpkg") %>% st_drop_geometry()
cov <- c("INTDEN", "GREEN_SP", "NOISE", "PM25", "NO2", "MEDREV", "R_UNEMP", "R_NN_POBL", "R_NN_CH")
data.obesity <- indiv %>%
inner_join(ha, by="reli") %>%
filter(!is.na(obesity_adj)) %>%
dplyr::select(obesity_adj, all_of(cov))
obesity.data <- indiv %>%
inner_join(ha, by="reli") %>%
filter(!is.na(obesity_adj)) %>%
dplyr::select(obesity_adj, all_of(cov))
obesity.ols <-lm(obesity_adj ~ INTDEN + GREEN_SP + NOISE + PM25 + NO2 + MEDREV + R_UNEMP + R_NN_POBL + R_NN_CH, data=obesity.data)
print_model_summary(obesity.ols)
summary(obesity.ols)
vif(obesity.ols)
extract_data_outcome <- function(df, hectares, outcome_name){
data <- df %>%
inner_join(hectares, by="reli") %>%
filter(!is.na(!!as.name(outcome_name))) %>%
dplyr::select(!!as.name(outcome_name), all_of(cov))
return(data)
}
extract_data_outcome(indiv, ha, "obesity_adk")
extract_data_outcome(indiv, ha, "obesity_adj")
obes.data <- extract_data_outcome(indiv, ha, "obesity_adj")
run_ols <- function(data, outcome_name){
ols <-lm(as.formula(paste0(outcome_name, '~  INTDEN + GREEN_SP + NOISE + PM25 + NO2 + MEDREV + R_UNEMP + R_NN_POBL + R_NN_CH')),
data=data)
summary(ols)
vif(ols)
}
run_ols(obes.data)
run_ols(obes.data, "obesity_adj")
run_ols <- function(data, outcome_name){
ols <-lm(as.formula(paste0(outcome_name, '~  INTDEN + GREEN_SP + NOISE + PM25 + NO2 + MEDREV + R_UNEMP + R_NN_POBL + R_NN_CH')),
data=data)
print(summary(ols))
print(vif(ols))
}
obes.data <- extract_data_outcome(indiv, ha, "obesity_adj")
run_ols(obes.data, "obesity_adj")
hyp.data <- extract_data_outcome(indiv, ha, "hypertension_adj")
run_ols(hyp.data, "hypertension_adj")
diab.data <- extract_data_outcome(indiv, ha, "diabetes_adj")
run_ols(diab.data, "diabetes_adj")
dys.data <- extract_data_outcome(indiv, ha, "dyslipidemia_adj")
run_ols(dys.data, "dyslipidemia_adj")
# Compute the Ordinatry Least Squares Regression (OLS) to be compared with GWR/MGWR, and that will be used to assess VIF
require(RPostgreSQL)
require(car)
require(tidyverse)
require(sf)
require(DBI)
setwd("/mnt/data/GEOSAN/RESEARCH PROJECTS/GEOCHRONIC @ LASIG (EPFL)/GEOSAN-geochronic/src/")
source('/mnt/data/GEOSAN/FUNCTIONS/GIRAPH-functions/geosan_funcs/password_utils.R')
con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",rstudioapi::askForPassword(),dbname="geosan")
# LOAD DATASETS -----------------------------------------------------------
ha <- read_sf(con, query="SELECT * FROM geochronic.ha_characteristics") %>% st_drop_geometry()
ha <- ha %>% rename_with(~ toupper(.), -c(reli))
indiv =  st_read("../processed_data/f2_adjusted_outcomes.gpkg") %>% st_drop_geometry()
cov <- c("INTDEN", "GREEN_SP", "NOISE", "PM25", "NO2", "MEDREV", "R_UNEMP", "R_NN_POBL", "R_NN_CH")
extract_data_outcome <- function(df, hectares, outcome_name){
data <- df %>%
inner_join(hectares, by="reli") %>%
filter(!is.na(!!as.name(outcome_name))) %>%
dplyr::select(!!as.name(outcome_name), all_of(cov))
return(data)
}
run_ols <- function(data, outcome_name){
ols <-lm(as.formula(paste0(outcome_name, '~  INTDEN + GREEN_SP + NOISE + PM25 + NO2 + MEDREV + R_UNEMP + R_NN_POBL + R_NN_CH')),
data=data)
print(summary(ols))
print(vif(ols))
}
hyp.data <- extract_data_outcome(indiv, ha, "hypertension_adj")
run_ols(hyp.data, "hypertension_adj")
require(tidyverse)
require(sf)
require(ggplot2)
require(viridis)
require(classInt)
require(ggspatial)
require(RPostgreSQL)
require(corrplot)
source('/mnt/data/GEOSAN/FUNCTIONS/GIRAPH-functions/geosan_funcs/password_utils.R')
setwd("/mnt/data/GEOSAN/RESEARCH PROJECTS/GEOCHRONIC @ LASIG (EPFL)/GEOSAN-geochronic/src/")
# con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",askForPassword(),dbname="geosan")
con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",rstudioapi::askForPassword(),dbname="geosan")
ha <- read_sf(con, query="SELECT reli, INTDEN, GREEN_SP, NOISE, PM25, NO2, MEDREV, R_UNEMP, R_NN_POBL, R_NN_CH, geometry FROM geochronic.ha_characteristics WHERE st_intersects(geometry, (SELECT geometry FROM lausanne_sectors_extent))")
#names(ha)[names(ha) != c("reli", "geometry")] <- toupper(names(ha)[names(ha) != c("reli", "geometry")])
columns_to_convert <- c("intden", "green_sp", "noise", "pm25", "no2", "medrev", "r_unemp", "r_nn_pobl", "r_nn_ch")
names(ha)[names(ha) %in% columns_to_convert] <- toupper(names(ha)[names(ha) %in% columns_to_convert])
lausanne <- read_sf(con, query="SELECT * FROM lausanne_sectors_extent")
lake <- st_read("../qgis/lake_border_buffered.geojson")
# SPATIAL DISTRIBUTION ----------------------------------------------------
choropleth_map <- function(ha_df, ind_name, legend_name, title_name, class_type="pretty", save=TRUE){
breaks <- classIntervals(ha_df %>% pull(!!as.name(ind_name)), n = 5, style = class_type)
p <- ggplot() +
geom_sf(data = lausanne, color = "grey", fill = NA, lwd=1.5) +
geom_sf(data = lake, fill = "#c9e5f3", color="#c9e5f3", alpha=1) +
geom_sf(data = ha_df, aes(fill = !!as.name(ind_name)), color = "white" , alpha=0.7) +
scale_fill_viridis(discrete = F,
name = legend_name,
breaks = breaks$brks,
labels = breaks$brks,
direction = 1,
guide = guide_colourbar(
direction = "horizontal",
barheight = unit(2, units = "mm"),
barwidth = unit(50, units = "mm"),
draw.ulim = F,
title.position = 'top',
title.hjust = 0.4,
label.hjust = 0.5)) +
theme_void() +
theme(plot.background = element_rect(fill = "#f5f5f2", color = NA),
panel.background = element_rect(fill = "#f5f5f2", color = NA),
plot.title = element_text(size = 16),
legend.position = c(0.2, 0.05),
legend.title = element_text(size = 12),
legend.text = element_text(size = 8),
text=element_text(family="Ubuntu Regular")) +
labs(x = NULL, y = NULL,
title = title_name,
#subtitle = "Source: Table QS502EW, Census 2011",
#caption = "Contains OS data © Crown copyright and database right (2018)"
) +
annotation_scale(location = "br", width_hint = 0.2, style="ticks")
ggsave(paste0("../results/env_characteristics/choropleth_", ind_name, ".png"),
bg="white", width=200, height=150, units=c("mm"), dpi=300)
return(p)
}
cov <- c("INTDEN", "GREEN_SP", "NOISE", "PM25", "NO2", "MEDREV", "R_UNEMP", "R_NN_POBL", "R_NN_CH")
choropleth_map(ha, "INTDEN", "Intersection Density (-)", "Street connectivity within a 500-meters radius buffer")
choropleth_map(ha, "GREEN_SP", "Greenness (%)", "Proportion of green spaces within a 500-meters radius buffer")
choropleth_map(ha, "NOISE", "Noise (dB)", "Nighttime Noise Exposure from Roadway and Railway Sources")
choropleth_map(ha, "PM25", "Concentration (ug/m3)", "Exposure to fine particulate matter PM2.5")
choropleth_map(ha, "NO2", "Concentration (ug/m3)", "Exposure to nitrogen dioxide (NO2)")
choropleth_map(ha, "MEDREV", "Income (kCHF)", "Median annual income per household")
choropleth_map(ha, "R_UNEMP", "Rate (%)", "Unemployment rate for population aged 15 and above")
choropleth_map(ha, "R_NN_POBL", "Rate (%)", "Population aged 15+ with compulsory education")
choropleth_map(ha, "R_NN_CH", "Rate (%)", "Proportion of foreign population")
# CORRELATION -------------------------------------------------------------
data_scaled <- ha %>%
st_drop_geometry() %>%
dplyr::select(all_of(cov)) %>%
filter(complete.cases(.)) %>%
scale()
corr_matrix <- cor(data_scaled)
print(corr_matrix)
png("../results/env_characteristics/corrplot.png", bg="white", width=200, height=150, units=c("mm"), res=300)
corrplot(corr_matrix,tl.col = "black")
dev.off()
require(tidyverse)
require(sf)
require(ggplot2)
require(viridis)
require(classInt)
require(ggspatial)
require(RPostgreSQL)
require(corrplot)
source('/mnt/data/GEOSAN/FUNCTIONS/GIRAPH-functions/geosan_funcs/password_utils.R')
setwd("/mnt/data/GEOSAN/RESEARCH PROJECTS/GEOCHRONIC @ LASIG (EPFL)/GEOSAN-geochronic/src/")
# con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",askForPassword(),dbname="geosan")
con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",rstudioapi::askForPassword(),dbname="geosan")
ha <- read_sf(con, query="SELECT reli, INTDEN, GREEN_SP, NOISE, PM25, NO2, MEDREV, R_UNEMP, R_NN_POBL, R_NN_CH, geometry FROM geochronic.ha_characteristics WHERE st_intersects(geometry, (SELECT geometry FROM lausanne_sectors_extent))")
#names(ha)[names(ha) != c("reli", "geometry")] <- toupper(names(ha)[names(ha) != c("reli", "geometry")])
columns_to_convert <- c("intden", "green_sp", "noise", "pm25", "no2", "medrev", "r_unemp", "r_nn_pobl", "r_nn_ch")
names(ha)[names(ha) %in% columns_to_convert] <- toupper(names(ha)[names(ha) %in% columns_to_convert])
lausanne <- read_sf(con, query="SELECT * FROM lausanne_sectors_extent")
lake <- st_read("../qgis/lake_border_buffered.geojson")
# SPATIAL DISTRIBUTION ----------------------------------------------------
choropleth_map <- function(ha_df, ind_name, legend_name, title_name, class_type="pretty", save=TRUE){
breaks <- classIntervals(ha_df %>% pull(!!as.name(ind_name)), n = 5, style = class_type)
p <- ggplot() +
geom_sf(data = lausanne, color = "grey", fill = NA, lwd=1.5) +
geom_sf(data = lake, fill = "#c9e5f3", color="#c9e5f3", alpha=1) +
geom_sf(data = ha_df, aes(fill = !!as.name(ind_name)), color = "white" , alpha=0.7) +
scale_fill_viridis(discrete = F,
name = legend_name,
breaks = breaks$brks,
labels = breaks$brks,
direction = 1,
guide = guide_colourbar(
direction = "horizontal",
barheight = unit(2, units = "mm"),
barwidth = unit(50, units = "mm"),
draw.ulim = F,
title.position = 'top',
title.hjust = 0.4,
label.hjust = 0.5)) +
theme_void() +
theme(plot.background = element_rect(fill = "#f5f5f2", color = NA),
panel.background = element_rect(fill = "#f5f5f2", color = NA),
plot.title = element_text(size = 16),
legend.position = c(0.2, 0.05),
legend.title = element_text(size = 12),
legend.text = element_text(size = 8),
text=element_text(family="Ubuntu Regular")) +
labs(x = NULL, y = NULL,
title = title_name,
#subtitle = "Source: Table QS502EW, Census 2011",
#caption = "Contains OS data © Crown copyright and database right (2018)"
) +
annotation_scale(location = "br", width_hint = 0.2, style="ticks")
ggsave(paste0("../results/env_characteristics/choropleth_", ind_name, ".png"),
bg="white", width=200, height=150, units=c("mm"), dpi=300)
return(p)
}
cov <- c("INTDEN", "GREEN_SP", "NOISE", "PM25", "NO2", "MEDREV", "R_UNEMP", "R_NN_POBL", "R_NN_CH")
choropleth_map(ha, "INTDEN", "Intersection Density (-)", "Street connectivity within a 500-meters radius buffer")
choropleth_map(ha, "GREEN_SP", "Greenness (%)", "Proportion of green spaces within a 500-meters radius buffer")
choropleth_map(ha, "NOISE", "Noise (dB)", "Daytime Noise Exposure from Roadway and Railway Sources")
choropleth_map(ha, "PM25", "Concentration (ug/m3)", "Exposure to fine particulate matter PM2.5")
choropleth_map(ha, "NO2", "Concentration (ug/m3)", "Exposure to nitrogen dioxide (NO2)")
choropleth_map(ha, "MEDREV", "Income (kCHF)", "Median annual income per household")
choropleth_map(ha, "R_UNEMP", "Rate (%)", "Unemployment rate for population aged 15 and above")
choropleth_map(ha, "R_NN_POBL", "Rate (%)", "Population aged 15+ with compulsory education")
choropleth_map(ha, "R_NN_CH", "Rate (%)", "Proportion of foreign population")
# CORRELATION -------------------------------------------------------------
data_scaled <- ha %>%
st_drop_geometry() %>%
dplyr::select(all_of(cov)) %>%
filter(complete.cases(.)) %>%
scale()
corr_matrix <- cor(data_scaled)
print(corr_matrix)
png("../results/env_characteristics/corrplot.png", bg="white", width=200, height=150, units=c("mm"), res=300)
corrplot(corr_matrix,tl.col = "black")
dev.off()
# Compute the Ordinatry Least Squares Regression (OLS) to be compared with GWR/MGWR, and that will be used to assess VIF
require(RPostgreSQL)
require(car)
require(tidyverse)
require(sf)
require(DBI)
setwd("/mnt/data/GEOSAN/RESEARCH PROJECTS/GEOCHRONIC @ LASIG (EPFL)/GEOSAN-geochronic/src/")
source('/mnt/data/GEOSAN/FUNCTIONS/GIRAPH-functions/geosan_funcs/password_utils.R')
con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",rstudioapi::askForPassword(),dbname="geosan")
# LOAD DATASETS -----------------------------------------------------------
ha <- read_sf(con, query="SELECT * FROM geochronic.ha_characteristics") %>% st_drop_geometry()
ha <- ha %>% rename_with(~ toupper(.), -c(reli))
indiv =  st_read("../processed_data/f2_adjusted_outcomes.gpkg") %>% st_drop_geometry()
cov <- c("INTDEN", "GREEN_SP", "NOISE", "PM25", "NO2", "MEDREV", "R_UNEMP", "R_NN_POBL", "R_NN_CH")
extract_data_outcome <- function(df, hectares, outcome_name){
data <- df %>%
inner_join(hectares, by="reli") %>%
filter(!is.na(!!as.name(outcome_name))) %>%
dplyr::select(!!as.name(outcome_name), all_of(cov))
return(data)
}
run_ols <- function(data, outcome_name){
ols <-lm(as.formula(paste0(outcome_name, '~  INTDEN + GREEN_SP + NOISE + PM25 + NO2 + MEDREV + R_UNEMP + R_NN_POBL + R_NN_CH')),
data=data)
print(summary(ols))
print(vif(ols))
}
hyp.data <- extract_data_outcome(indiv, ha, "hypertension_adj")
run_ols(hyp.data, "hypertension_adj")
obes.data <- extract_data_outcome(indiv, ha, "obesity_adj")
run_ols(obes.data, "obesity_adj")
diab.data <- extract_data_outcome(indiv, ha, "diabetes_adj")
run_ols(diab.data, "diabetes_adj")
dys.data <- extract_data_outcome(indiv, ha, "dyslipidemia_adj")
run_ols(dys.data, "dyslipidemia_adj")
DBI::dbDisconnect(con)
require(tidyverse)
require(sf)
require(ggplot2)
require(viridis)
require(classInt)
require(ggspatial)
require(RPostgreSQL)
require(corrplot)
source('/mnt/data/GEOSAN/FUNCTIONS/GIRAPH-functions/geosan_funcs/password_utils.R')
setwd("/mnt/data/GEOSAN/RESEARCH PROJECTS/GEOCHRONIC @ LASIG (EPFL)/GEOSAN-geochronic/src/")
# con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",askForPassword(),dbname="geosan")
con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",rstudioapi::askForPassword(),dbname="geosan")
require(tidyverse)
require(sf)
require(ggplot2)
require(viridis)
require(classInt)
require(ggspatial)
require(RPostgreSQL)
require(corrplot)
source('/mnt/data/GEOSAN/FUNCTIONS/GIRAPH-functions/geosan_funcs/password_utils.R')
setwd("/mnt/data/GEOSAN/RESEARCH PROJECTS/GEOCHRONIC @ LASIG (EPFL)/GEOSAN-geochronic/src/")
# con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",askForPassword(),dbname="geosan")
con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",rstudioapi::askForPassword(),dbname="geosan")
ha <- read_sf(con, query="SELECT reli, INTDEN, GREEN_SP, NOISE, PM25, NO2, MEDREV, R_UNEMP, R_NN_POBL, R_NN_CH, geometry FROM geochronic.ha_characteristics WHERE st_intersects(geometry, (SELECT geometry FROM lausanne_sectors_extent))")
#names(ha)[names(ha) != c("reli", "geometry")] <- toupper(names(ha)[names(ha) != c("reli", "geometry")])
columns_to_convert <- c("intden", "green_sp", "noise", "pm25", "no2", "medrev", "r_unemp", "r_nn_pobl", "r_nn_ch")
names(ha)[names(ha) %in% columns_to_convert] <- toupper(names(ha)[names(ha) %in% columns_to_convert])
lausanne <- read_sf(con, query="SELECT * FROM lausanne_sectors_extent")
lake <- st_read("../qgis/lake_border_buffered.geojson")
# SPATIAL DISTRIBUTION ----------------------------------------------------
choropleth_map <- function(ha_df, ind_name, legend_name, title_name, class_type="pretty", save=TRUE){
breaks <- classIntervals(ha_df %>% pull(!!as.name(ind_name)), n = 5, style = class_type)
p <- ggplot() +
geom_sf(data = lausanne, color = "grey", fill = NA, lwd=1.5) +
geom_sf(data = lake, fill = "#c9e5f3", color="#c9e5f3", alpha=1) +
geom_sf(data = ha_df, aes(fill = !!as.name(ind_name)), color = "white" , alpha=0.7) +
scale_fill_viridis(discrete = F,
name = legend_name,
breaks = breaks$brks,
labels = breaks$brks,
direction = 1,
guide = guide_colourbar(
direction = "horizontal",
barheight = unit(2, units = "mm"),
barwidth = unit(50, units = "mm"),
draw.ulim = F,
title.position = 'top',
title.hjust = 0.4,
label.hjust = 0.5)) +
theme_void() +
theme(plot.background = element_rect(fill = "#f5f5f2", color = NA),
panel.background = element_rect(fill = "#f5f5f2", color = NA),
plot.title = element_text(size = 16),
legend.position = c(0.2, 0.05),
legend.title = element_text(size = 12),
legend.text = element_text(size = 8),
text=element_text(family="Ubuntu Regular")) +
labs(x = NULL, y = NULL,
title = title_name,
#subtitle = "Source: Table QS502EW, Census 2011",
#caption = "Contains OS data © Crown copyright and database right (2018)"
) +
annotation_scale(location = "br", width_hint = 0.2, style="ticks")
ggsave(paste0("../results/env_characteristics/choropleth_", ind_name, ".png"),
bg="white", width=200, height=150, units=c("mm"), dpi=300)
return(p)
}
cov <- c("INTDEN", "GREEN_SP", "NOISE", "PM25", "NO2", "MEDREV", "R_UNEMP", "R_NN_POBL", "R_NN_CH")
choropleth_map(ha, "INTDEN", "Intersection Density (-)", "Street connectivity within a 500-meters radius buffer")
choropleth_map(ha, "GREEN_SP", "Greenness (%)", "Proportion of green spaces within a 500-meters radius buffer")
choropleth_map(ha, "NOISE", "Noise (dB)", "Nihgttime Noise Exposure from Roadway and Railway Sources")
choropleth_map(ha, "PM25", "Concentration (ug/m3)", "Exposure to fine particulate matter PM2.5")
choropleth_map(ha, "NO2", "Concentration (ug/m3)", "Exposure to nitrogen dioxide (NO2)")
choropleth_map(ha, "MEDREV", "Income (kCHF)", "Median annual income per household")
choropleth_map(ha, "R_UNEMP", "Rate (%)", "Unemployment rate for population aged 15 and above")
choropleth_map(ha, "R_NN_POBL", "Rate (%)", "Population aged 15+ with compulsory education")
choropleth_map(ha, "R_NN_CH", "Rate (%)", "Proportion of foreign population")
# CORRELATION -------------------------------------------------------------
data_scaled <- ha %>%
st_drop_geometry() %>%
dplyr::select(all_of(cov)) %>%
filter(complete.cases(.)) %>%
scale()
corr_matrix <- cor(data_scaled)
print(corr_matrix)
png("../results/env_characteristics/corrplot.png", bg="white", width=200, height=150, units=c("mm"), res=300)
corrplot(corr_matrix,tl.col = "black")
dev.off()
# This code run descriptive statistics about Colaus participants
library(tidyverse)
library(sf)
library(RPostgreSQL)
library(stats)
source('/mnt/data/GEOSAN/FUNCTIONS/GIRAPH-functions/geosan_funcs/password_utils.R')
setwd("/mnt/data/GEOSAN/RESEARCH PROJECTS/GEOCHRONIC @ LASIG (EPFL)/GEOSAN-geochronic/src/")
con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",askForPassword(),dbname="geosan")
