---
title: "Modeling - Chronic diseases"
author: "Anaïs Ladoy"
date: '2023-04-09'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/mnt/data/GEOSAN/RESEARCH PROJECTS/GEOCHRONIC @ LASIG (EPFL)/GEOSAN-geochronic/src")
```

```{r, include=FALSE}
library(stats)
library(lme4)
library(RPostgreSQL)
library(MASS)
library(MapGAM)
library(pROC)
library(mgcv)
library(gam)
library(logbin) # Log-binomial regression
library(jtools)
library(PrevMap)
source('/mnt/data/GEOSAN/FUNCTIONS/GIRAPH-functions/geosan_funcs/password_utils.R')
source('modeling/utils_model_individual_outcomes.R')
```

```{r, include=FALSE}
con <- dbConnect(drv=RPostgreSQL::PostgreSQL(),host = "localhost",user= "aladoy",rstudioapi::askForPassword(),dbname="geosan")
```

### Import the datasets

- `data`: All F2 Colaus participants eligible for this study (see selection procedure).
- `env`: Neighborhood characteristics build in **explore_neighborhood_characteristics.Rmd**

```{r, include=FALSE}
data <- load_participants(con)
data <- add_env_info(data)
```

- `boundary.laus`: Boundary of the Lausanne area (polygon)
- `boundary.vd`: Boundary of the Vaud state (polygon)

```{r, include=FALSE}
extent <- load_boundaries(con)
```

- `predict.grid`: Prediction grid for Vaud state (inhabited hectares only)

```{r, include=FALSE}
grid.sf <- read_sf("../processed_data/neighborhood_vd.gpkg")
grid <- grid.sf %>% st_drop_geometry()
```



```{r}
cov.indiv <- c("age", "sex", "swiss", "cohabiting", "education", "working", "difficulties", "smoking", "drinking", "inactivity", "out_laus")

cov.env <- c("PTOT", "D_SPORT", "N_ACC_PED", "GREEN_SP", "ENV_INDEX", "SOC_ECO_INDEX", "SWISS", "UNEMPLOYMENT", "LOW_EDUC", "INCOME", "HH_1PERS")

cov.demo <- c("F_45_54", "F_55_64", "F_65_74", "F_75_MORE", "M_45_54", "M_55_64", "M_65_74", "M_75_MORE")

cov.continuous <- c("age", cov.env)
```

I removed HIGH_EDUC because highly correlated with LOW_EDUC in the model but the spatial pattern is different (see spatial_clustering_outcomes). Should I include both?
Same for poverty and income. Easier to predict with a binary variable but we loose some granularity and both are correlated. What should we keep in the model? For now, I kept income.

# Diabetes

```{r}
diab.data <- select_outcome_regression(data, "diabetes", cov.indiv, cov.env)
```

Distribution of age and neighborhood-related characteristics between cases and controls.
```{r}
plot_cov_distribution(diab.data, "diabetes", cov.continuous)
```


### 1. Investigate the individual-level covariates using a logistic regression

**Log-binomial regression**
Provides more robust estimates of Prevalence Ratio than logistic regression for prevalence > 10 % (Barros et al., 2003).
Another option is 

```{r}
diab.logbin <- diab.data %>% select(diabetes, cov.indiv)
m <- logbin(diabetes ~ age + sex + swiss + cohabiting  + difficulties + education + smoking + drinking + inactivity, data=diab.logbin)
```

Changer la manière de calculer l'indice de vulnérabilité socio-économique?

**Generalized Linear Model**

```{r}
m.univ <- glm(diabetes ~ sex, data=diab.data, family='binomial')
print_model_summary(m.univ)
```

- `Deviance residuals`: should be centered around 0 and symmetrical. 
- `Coefficients`: give the log-odds estimates. Effect size.
- `Dispersion parameter`: since the variance is derived from the estimated mean (compared to the linear regression where we estimate both the mean and the variance from the data), it can be underestimated and we can adjust this by adjusting the dispersion parameter.
- `Null and Residual Deviance`: can be used to compare models, compute R^2 and an overall p-value.
- `AIC`: Akaike Information Criterion, which is here the residual deviance adjusted for the number of parameters in the model. Can be used to compare models.
- `Fisher Scoring Iterations`: how quickly the glm() function converged on the maximum likelihood estimates for the coefficients.

*Compare models:* Better model will have lower residual deviance and lower AIC.  
*Specification error*: we must particularly check here if our model has all relevant predictors, and if the linear combinations of them is sufficient.


```{r, fig.width=3,fig.height=2}
paste("The probability that a man has diabetes is", inverse_logit(m.univ$coefficients[[1]]))
paste("The probability that a woman has diabetes is", inverse_logit(m.univ$coefficients[[1]] + m.univ$coefficients[[2]]))
paste("Women are", round(1/exp(m.univ$coefficients[[2]]),2), "less likely to have diabetes than a man.")
mcfadden(m.univ)
```

**Investigate individual-level covariates using a backward stepwise logistic regression.**

```{r}
glm.indiv <- stepwise_logistic_regression(diab.data, "diabetes", cov.indiv, trace=0)
```

**Test if we should model age as non-linear to diabetes (with cubic spline)**

```{r}
gam.indiv <- mgcv::gam(diabetes ~ s(age, bs="cr") + sex + swiss + education + working + difficulties + smoking + inactivity, method = "GCV.Cp", data=diab.data, family="binomial")
print_model_summary(gam.indiv, type="gam")
```

```{r}
compare_models(glm.indiv, gam.indiv)
```

Model age with a non-linear function significantly improved the model with individual covariates only.

**Plot the cubic splines used to model the diabetes-age relationship**

```{r}
plot(gam.indiv, cex.lab=0.8, cex.axis=0.8)
```

Not a problem if there are covariates with p-value > 0.05 in the model returned by the stepwise regression model. The stepwise returned the model with the lowest AIC, so the better. We keep the variables in the paper while specifying there are not significant.



**Select the best model for individual-covariates only**

```{r}
m.indiv <- gam.indiv
diab.cov.indiv <- c("age", "sex", "swiss", "education", "working", "difficulties", "smoking", "inactivity")
```



### 2.Assess the impact of the environment at the individual level


With socio-eco / environment and without demographic characteristics
```{r}
glm.env <- stepwise_logistic_regression(diab.data, "diabetes", c(diab.cov.indiv, cov.env), trace=0)
```

```{r}
gam.env.all <- update(m.indiv, '~ . + s(SOC_ECO_INDEX, bs="cr") + s(INCOME, bs="cr")')
print_model_summary(gam.env.all, type="gam")
```
Even if the smooth term is significant for the SOC_ECO_INDEX term, the regression spline seems quite linear for both the socio-economic and the income term (`plot.gam(gam.env, select = 2)`, `plot.gam(gam.env, select = 3)`). Therefore, we model these two variables as linear relationship.

```{r}
gam.env <- update(m.indiv, '~ . + SOC_ECO_INDEX + INCOME')
print_model_summary(gam.env, type="gam")
```



```{r}
compare_models(glm.env, gam.env)
```


```{r}
compare_models(m.indiv, gam.env)
```


### 3. Incorporate spatial effects

Try an empty 2-levels regression model. 
Determine to what extent do the log-odds vary between clusters using the intraclass correlation coefficient (ICC). The ICC quantifies the degree of homogeneity of the outcome within clusters, and represents the proportion of the between-cluster variation in the total variation.

```{r}
m <- empty_multilevel(diab.data, "diabetes", "reli")
```
The variance and standard deviation of the random intercept for the grouping variable "reli" is close to 0. Therefore, it indicates very little variability between groups, and that the group-level interecepts is almost identical.


Generalized Additive Model (GAM) with a two-dimensional LOESS smooth.
```{r}
gam.loess <- update(gam.env, ~ . + lo(coordx, coordy, span=0.3))
summary(gam.loess)
```

```{r}
compare_models(gam.env, gam.loess)
```
Adding a LOESS spatial smoother does not improve significantly the model. We therefore keep the previous model.

```{r}
m.final <- gam.env
diab.cov.env <- c("SOC_ECO_INDEX", "INCOME")
```




### Predict 

```{r}
d <- data %>% select(diabetes, all_of(cov.demo), PTOT, SWISS, LOW_EDUC, UNEMPLOYMENT, INCOME)

```

```{r}
gam.loess <- gam(diabetes ~ F_55_64 + M_65_74 + GREEN_SP + SOC_ECO_INDEX + LOW_EDUC + INCOME + lo(coordx, coordy, span=0.3), data=data, family=binomial())
```

```{r}
summary(gam.loess)
```


```{r}
glm.env <- stepwise_logistic_regression(data, "diabetes", c(cov.demo, cov.env), trace=0)
```

```{r}
grid.sf <- grid.sf %>% mutate(pred_prob = predict(glm.env, grid, type="response"))
```

```{r}
write_sf(grid.sf, "grid_sf_diabetes.gpkg")
```


```{r}
m.univ <- glm(diabetes ~ ., data=d, family='binomial')
print_model_summary(m.univ)

```





